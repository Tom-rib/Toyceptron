# 04 - Impl√©mentation : Neuron

> Coder la classe Neuron, l'unit√© de calcul √©l√©mentaire

---

## üéØ Objectif

Cr√©er la classe `Neuron` dans le fichier `src/neuron.py` qui :
- Stocke des **poids** (weights) et un **biais** (bias)
- Calcule une **sortie** √† partir d'un vecteur d'entr√©e
- Applique une **fonction d'activation**

---

## üìã Sp√©cifications

### Attributs de la classe
```python
class Neuron:
    def __init__(self, weights, bias):
        self.weights = weights  # Liste de nombres (poids)
        self.bias = bias        # Nombre (biais)
```

### M√©thodes requises
```python
def compute(self, inputs, activation):
    """
    Calcule la sortie du neurone.
    
    Args:
        inputs (list): Vecteur d'entr√©e [x1, x2, ..., xn]
        activation (function): Fonction d'activation √† appliquer
        
    Returns:
        float: Sortie du neurone apr√®s activation
    """
    # √Ä impl√©menter
```

---

## üßÆ Algorithme

### √âtape 1 : Produit scalaire + biais
```
z = w1¬∑x1 + w2¬∑x2 + ... + wn¬∑xn + b
```

### √âtape 2 : Activation
```
y = activation(z)
```

### Sch√©ma du calcul
```
Entr√©es      Poids       Somme pond√©r√©e    Activation    Sortie
[x1, x2] ‚Üí [w1, w2] ‚Üí Œ£(wi¬∑xi) + b ‚Üí f(z) ‚Üí y
```

---

## üíª Impl√©mentation pas √† pas

### √âtape 1 : Squelette de la classe

Ouvre `src/neuron.py` et commence par :

```python
# src/neuron.py

class Neuron:
    """
    Classe repr√©sentant un neurone artificiel.
    
    Un neurone effectue une combinaison lin√©aire de ses entr√©es,
    ajoute un biais, puis applique une fonction d'activation.
    """
    
    def __init__(self, weights, bias):
        """
        Initialise le neurone.
        
        Args:
            weights (list): Liste des poids [w1, w2, ..., wn]
            bias (float): Biais du neurone
        """
        self.weights = weights
        self.bias = bias
    
    def compute(self, inputs, activation):
        """
        Calcule la sortie du neurone.
        
        Args:
            inputs (list): Vecteur d'entr√©e [x1, x2, ..., xn]
            activation (function): Fonction d'activation
            
        Returns:
            float: Sortie du neurone
        """
        # TODO: Impl√©menter le calcul
        pass
```

---

### √âtape 2 : Impl√©menter le produit scalaire

Le produit scalaire est : `Œ£(wi ¬∑ xi) = w1¬∑x1 + w2¬∑x2 + ... + wn¬∑xn`

**M√©thode 1 : Avec une boucle for**
```python
def weighted_sum(self, inputs):
    """
    Calcule la somme pond√©r√©e des entr√©es.
    
    Args:
        inputs (list): Vecteur d'entr√©e
        
    Returns:
        float: Œ£(wi ¬∑ xi) + bias
    """
    total = 0.0
    for i in range(len(inputs)):
        total += self.weights[i] * inputs[i]
    
    return total + self.bias
```

**M√©thode 2 : Avec zip() (plus pythonique)**
```python
def weighted_sum(self, inputs):
    """
    Calcule la somme pond√©r√©e des entr√©es.
    """
    total = sum(w * x for w, x in zip(self.weights, inputs))
    return total + self.bias
```

**M√©thode 3 : Avec une compr√©hension de liste**
```python
def weighted_sum(self, inputs):
    """
    Calcule la somme pond√©r√©e des entr√©es.
    """
    total = sum([self.weights[i] * inputs[i] for i in range(len(inputs))])
    return total + self.bias
```

**Choisis la m√©thode qui te semble la plus claire !**

---

### √âtape 3 : Compl√©ter la m√©thode compute()

```python
def compute(self, inputs, activation):
    """
    Calcule la sortie du neurone.
    
    Args:
        inputs (list): Vecteur d'entr√©e
        activation (function): Fonction d'activation
        
    Returns:
        float: Sortie du neurone apr√®s activation
    """
    # √âtape 1 : Calculer la somme pond√©r√©e
    z = self.weighted_sum(inputs)
    
    # √âtape 2 : Appliquer l'activation
    y = activation(z)
    
    return y
```

---

## üìù Code complet de neuron.py

Voici le code complet (choisis ta m√©thode pr√©f√©r√©e pour le produit scalaire) :

```python
# src/neuron.py

class Neuron:
    """
    Classe repr√©sentant un neurone artificiel.
    
    Attributs:
        weights (list): Poids du neurone
        bias (float): Biais du neurone
    """
    
    def __init__(self, weights, bias):
        """
        Initialise le neurone avec des poids et un biais.
        
        Args:
            weights (list): Liste des poids [w1, w2, ..., wn]
            bias (float): Biais du neurone
        """
        self.weights = weights
        self.bias = bias
    
    def weighted_sum(self, inputs):
        """
        Calcule la somme pond√©r√©e : Œ£(wi ¬∑ xi) + bias
        
        Args:
            inputs (list): Vecteur d'entr√©e [x1, x2, ..., xn]
            
        Returns:
            float: Somme pond√©r√©e + biais
        """
        # M√©thode avec zip() (recommand√©e)
        total = sum(w * x for w, x in zip(self.weights, inputs))
        return total + self.bias
    
    def compute(self, inputs, activation):
        """
        Calcule la sortie du neurone.
        
        Processus:
        1. Calculer z = Œ£(wi ¬∑ xi) + bias
        2. Appliquer activation: y = f(z)
        
        Args:
            inputs (list): Vecteur d'entr√©e
            activation (function): Fonction d'activation √† appliquer
            
        Returns:
            float: Sortie du neurone apr√®s activation
        """
        z = self.weighted_sum(inputs)
        y = activation(z)
        return y
```

---

## üß™ Tests de validation

Cr√©e un fichier `test_neuron.py` pour tester ton neurone :

```python
# test_neuron.py
from neuron import Neuron

# Fonctions d'activation simples pour les tests
def identity(x):
    return x

def relu(x):
    return max(0, x)

# Test 1 : Neurone simple avec activation identit√©
print("=== Test 1 : Activation identit√© ===")
neuron = Neuron(weights=[1, 1, 1], bias=0)
output = neuron.compute([1, 2, 3], activation=identity)
print(f"Entr√©e : [1, 2, 3]")
print(f"Poids : [1, 1, 1], Biais : 0")
print(f"Sortie attendue : 6.0 (1+2+3)")
print(f"Sortie obtenue : {output}")
print(f"Test {'‚úÖ OK' if output == 6.0 else '‚ùå FAIL'}\n")

# Test 2 : Neurone avec biais
print("=== Test 2 : Avec biais ===")
neuron = Neuron(weights=[0.5, -0.3, 0.2], bias=0.1)
output = neuron.compute([1, 2, 3], activation=identity)
expected = 0.5*1 + (-0.3)*2 + 0.2*3 + 0.1  # = 0.6
print(f"Entr√©e : [1, 2, 3]")
print(f"Poids : [0.5, -0.3, 0.2], Biais : 0.1")
print(f"Sortie attendue : {expected}")
print(f"Sortie obtenue : {output}")
print(f"Test {'‚úÖ OK' if abs(output - expected) < 0.001 else '‚ùå FAIL'}\n")

# Test 3 : ReLU avec valeur n√©gative
print("=== Test 3 : ReLU avec valeur n√©gative ===")
neuron = Neuron(weights=[-1, -1], bias=0)
output = neuron.compute([1, 2], activation=relu)
print(f"Entr√©e : [1, 2]")
print(f"Poids : [-1, -1], Biais : 0")
print(f"z = -3, ReLU(-3) = 0")
print(f"Sortie attendue : 0")
print(f"Sortie obtenue : {output}")
print(f"Test {'‚úÖ OK' if output == 0 else '‚ùå FAIL'}\n")

# Test 4 : ReLU avec valeur positive
print("=== Test 4 : ReLU avec valeur positive ===")
neuron = Neuron(weights=[1, 1], bias=0)
output = neuron.compute([1, 2], activation=relu)
print(f"Entr√©e : [1, 2]")
print(f"z = 3, ReLU(3) = 3")
print(f"Sortie attendue : 3")
print(f"Sortie obtenue : {output}")
print(f"Test {'‚úÖ OK' if output == 3 else '‚ùå FAIL'}\n")

print("=== Tests termin√©s ===")
```

**Lancer les tests :**
```bash
cd src
python test_neuron.py
```

**Sortie attendue :**
```
=== Test 1 : Activation identit√© ===
...
Test ‚úÖ OK

=== Test 2 : Avec biais ===
...
Test ‚úÖ OK

=== Test 3 : ReLU avec valeur n√©gative ===
...
Test ‚úÖ OK

=== Test 4 : ReLU avec valeur positive ===
...
Test ‚úÖ OK

=== Tests termin√©s ===
```

---

## üêõ Debugging

### Erreur : "list index out of range"

**Probl√®me :** Les listes `weights` et `inputs` n'ont pas la m√™me longueur.

**Solution :**
```python
# Ajouter une v√©rification
def weighted_sum(self, inputs):
    if len(inputs) != len(self.weights):
        raise ValueError(f"Incompatibilit√© : {len(inputs)} entr√©es, {len(self.weights)} poids")
    # ... reste du code
```

---

### Erreur : "TypeError: 'NoneType' object is not callable"

**Probl√®me :** La fonction d'activation n'est pas pass√©e correctement.

**Solution :** V√©rifie que tu passes bien une fonction :
```python
# ‚úÖ Bon
output = neuron.compute([1, 2], activation=relu)

# ‚ùå Mauvais
output = neuron.compute([1, 2], activation=relu())  # Ne pas mettre ()
```

---

### R√©sultat incorrect

**Debugging :** Ajoute des prints pour voir les valeurs interm√©diaires :
```python
def compute(self, inputs, activation):
    print(f"Inputs : {inputs}")
    print(f"Weights : {self.weights}")
    print(f"Bias : {self.bias}")
    
    z = self.weighted_sum(inputs)
    print(f"z (avant activation) : {z}")
    
    y = activation(z)
    print(f"y (apr√®s activation) : {y}")
    
    return y
```

---

## ‚úÖ V√©rification finale

Avant de passer √† la suite, v√©rifie que :

- [ ] La classe `Neuron` est dans `src/neuron.py`
- [ ] Le constructeur `__init__()` stocke les poids et le biais
- [ ] La m√©thode `weighted_sum()` calcule le produit scalaire + biais
- [ ] La m√©thode `compute()` applique l'activation
- [ ] Tous les tests passent (4/4 ‚úÖ)
- [ ] Tu comprends chaque ligne de code

---

## üéØ R√©sum√©

Tu as cr√©√© un **neurone artificiel** capable de :
1. Stocker des poids et un biais
2. Calculer une combinaison lin√©aire des entr√©es
3. Appliquer une fonction d'activation
4. Retourner une sortie

**C'est la brique de base de tout r√©seau de neurones !** üéâ

---

## üìö Pour aller plus loin

### Bonus 1 : Initialisation al√©atoire

Ajoute une m√©thode pour initialiser des poids al√©atoires :
```python
import random

@staticmethod
def random_init(num_inputs):
    """
    Cr√©e un neurone avec des poids al√©atoires.
    
    Args:
        num_inputs (int): Nombre d'entr√©es
        
    Returns:
        Neuron: Neurone avec poids al√©atoires
    """
    weights = [random.uniform(-1, 1) for _ in range(num_inputs)]
    bias = random.uniform(-1, 1)
    return Neuron(weights, bias)
```

### Bonus 2 : M√©thode __str__

Ajoute une repr√©sentation lisible :
```python
def __str__(self):
    return f"Neuron(weights={self.weights}, bias={self.bias})"
```

---

**Prochaine √©tape :** [05 - Impl√©mentation Layer](05_implementation_layer.md)
