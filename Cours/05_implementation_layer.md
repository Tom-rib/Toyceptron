# 05 - ImplÃ©mentation : Layer

> Coder la classe Layer, une collection de neurones

---

## ğŸ¯ Objectif

CrÃ©er la classe `Layer` dans le fichier `src/layer.py` qui :
- Contient plusieurs **neurones**
- Applique tous les neurones Ã  un **vecteur d'entrÃ©e**
- Retourne un **vecteur de sortie**

---

## ğŸ“‹ SpÃ©cifications

### Attributs de la classe
```python
class Layer:
    def __init__(self, num_neurons, num_inputs):
        self.neurons = []  # Liste de Neuron
        # CrÃ©er num_neurons neurones
        # Chaque neurone aura num_inputs poids
```

### MÃ©thode requise
```python
def forward(self, inputs, activation):
    """
    Propage l'entrÃ©e Ã  travers tous les neurones.
    
    Args:
        inputs (list): Vecteur d'entrÃ©e
        activation (function): Fonction d'activation
        
    Returns:
        list: Vecteur de sortie [y1, y2, ..., yn]
    """
    # Ã€ implÃ©menter
```

---

## ğŸ§® Principe de fonctionnement

### SchÃ©ma d'une couche
```
EntrÃ©e (3 valeurs)       Couche (4 neurones)     Sortie (4 valeurs)

    x1  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  [neurone 1]  â”€â”€â”€â”€â†’  y1
    x2  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  [neurone 2]  â”€â”€â”€â”€â†’  y2
    x3  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  [neurone 3]  â”€â”€â”€â”€â†’  y3
                        [neurone 4]  â”€â”€â”€â”€â†’  y4
```

**Chaque neurone :**
- ReÃ§oit **la mÃªme entrÃ©e** `[x1, x2, x3]`
- A ses **propres poids et biais**
- Produit **une sortie**

**La couche :**
- Collecte toutes les sorties
- Retourne `[y1, y2, y3, y4]`

---

## ğŸ’¡ Algorithme

### Ã‰tape 1 : CrÃ©er les neurones

Pour une couche avec :
- `num_neurons` = 3 neurones
- `num_inputs` = 2 entrÃ©es par neurone

On doit crÃ©er 3 neurones, chacun avec 2 poids.

### Ã‰tape 2 : Forward pass

Pour chaque neurone dans la couche :
1. Appliquer le neurone Ã  l'entrÃ©e
2. Stocker la sortie dans une liste
3. Retourner la liste des sorties

**Pseudo-code :**
```
outputs = []
pour chaque neurone dans la couche:
    output = neurone.compute(inputs, activation)
    outputs.append(output)
retourner outputs
```

---

## ğŸ’» ImplÃ©mentation pas Ã  pas

### Ã‰tape 1 : Squelette de la classe

Ouvre `src/layer.py` :

```python
# src/layer.py
from neuron import Neuron
import random

class Layer:
    """
    Classe reprÃ©sentant une couche de neurones.
    
    Une couche contient plusieurs neurones qui reÃ§oivent
    tous la mÃªme entrÃ©e et produisent chacun une sortie.
    """
    
    def __init__(self, num_neurons, num_inputs):
        """
        Initialise une couche de neurones.
        
        Args:
            num_neurons (int): Nombre de neurones dans la couche
            num_inputs (int): Nombre d'entrÃ©es par neurone
        """
        self.neurons = []
        
        # TODO: CrÃ©er num_neurons neurones
        # Chaque neurone aura num_inputs poids
    
    def forward(self, inputs, activation):
        """
        Propage l'entrÃ©e Ã  travers la couche.
        
        Args:
            inputs (list): Vecteur d'entrÃ©e
            activation (function): Fonction d'activation
            
        Returns:
            list: Vecteur de sortie
        """
        # TODO: ImplÃ©menter la propagation
        pass
```

---

### Ã‰tape 2 : CrÃ©er les neurones dans __init__

Il y a **2 options** pour initialiser les neurones :

#### Option A : Poids alÃ©atoires (recommandÃ©)

```python
def __init__(self, num_neurons, num_inputs):
    """
    Initialise une couche avec des poids alÃ©atoires.
    """
    self.neurons = []
    
    # CrÃ©er num_neurons neurones
    for _ in range(num_neurons):
        # Poids alÃ©atoires entre -1 et 1
        weights = [random.uniform(-1, 1) for _ in range(num_inputs)]
        bias = random.uniform(-1, 1)
        
        # CrÃ©er le neurone et l'ajouter Ã  la couche
        neuron = Neuron(weights, bias)
        self.neurons.append(neuron)
```

#### Option B : Poids fixes (pour debug)

```python
def __init__(self, num_neurons, num_inputs):
    """
    Initialise une couche avec des poids fixes.
    """
    self.neurons = []
    
    for _ in range(num_neurons):
        # Poids fixes (tous Ã  0.5)
        weights = [0.5] * num_inputs
        bias = 0.0
        
        neuron = Neuron(weights, bias)
        self.neurons.append(neuron)
```

**Choisis l'option A (alÃ©atoire) pour avoir un vrai rÃ©seau.**

---

### Ã‰tape 3 : ImplÃ©menter forward()

```python
def forward(self, inputs, activation):
    """
    Propage l'entrÃ©e Ã  travers tous les neurones.
    
    Args:
        inputs (list): Vecteur d'entrÃ©e [x1, x2, ..., xn]
        activation (function): Fonction d'activation
        
    Returns:
        list: Vecteur de sortie [y1, y2, ..., ym]
    """
    outputs = []
    
    # Pour chaque neurone dans la couche
    for neuron in self.neurons:
        # Calculer la sortie de ce neurone
        output = neuron.compute(inputs, activation)
        outputs.append(output)
    
    return outputs
```

**Version avec comprÃ©hension de liste (plus concise) :**
```python
def forward(self, inputs, activation):
    return [neuron.compute(inputs, activation) for neuron in self.neurons]
```

---

## ğŸ“ Code complet de layer.py

```python
# src/layer.py
from neuron import Neuron
import random

class Layer:
    """
    Classe reprÃ©sentant une couche de neurones.
    
    Attributs:
        neurons (list): Liste des neurones de la couche
    """
    
    def __init__(self, num_neurons, num_inputs):
        """
        Initialise une couche de neurones avec poids alÃ©atoires.
        
        Args:
            num_neurons (int): Nombre de neurones dans la couche
            num_inputs (int): Nombre d'entrÃ©es par neurone (= taille du vecteur d'entrÃ©e)
        """
        self.neurons = []
        
        # CrÃ©er num_neurons neurones
        for _ in range(num_neurons):
            # Initialiser des poids alÃ©atoires entre -1 et 1
            weights = [random.uniform(-1, 1) for _ in range(num_inputs)]
            bias = random.uniform(-1, 1)
            
            # CrÃ©er et ajouter le neurone
            neuron = Neuron(weights, bias)
            self.neurons.append(neuron)
    
    def forward(self, inputs, activation):
        """
        Propage le vecteur d'entrÃ©e Ã  travers la couche.
        
        Processus:
        1. Pour chaque neurone, calculer sa sortie
        2. Collecter toutes les sorties dans une liste
        
        Args:
            inputs (list): Vecteur d'entrÃ©e
            activation (function): Fonction d'activation Ã  appliquer
            
        Returns:
            list: Vecteur de sortie [y1, y2, ..., yn]
        """
        outputs = []
        
        for neuron in self.neurons:
            output = neuron.compute(inputs, activation)
            outputs.append(output)
        
        return outputs
```

---

## ğŸ§ª Tests de validation

CrÃ©e `test_layer.py` pour tester ta couche :

```python
# test_layer.py
from layer import Layer

# Fonction d'activation simple
def identity(x):
    return x

def relu(x):
    return max(0, x)

# Test 1 : CrÃ©ation d'une couche
print("=== Test 1 : CrÃ©ation d'une couche ===")
layer = Layer(num_neurons=3, num_inputs=2)
print(f"Nombre de neurones crÃ©Ã©s : {len(layer.neurons)}")
print(f"Nombre de poids du 1er neurone : {len(layer.neurons[0].weights)}")
print(f"Test {'âœ… OK' if len(layer.neurons) == 3 else 'âŒ FAIL'}\n")

# Test 2 : Forward pass
print("=== Test 2 : Forward pass ===")
layer = Layer(num_neurons=4, num_inputs=3)
inputs = [1.0, 0.5, -0.3]
outputs = layer.forward(inputs, activation=identity)
print(f"EntrÃ©e : {inputs}")
print(f"Nombre de sorties : {len(outputs)}")
print(f"Sorties : {outputs}")
print(f"Test {'âœ… OK' if len(outputs) == 4 else 'âŒ FAIL'}\n")

# Test 3 : Taille de sortie
print("=== Test 3 : Taille de sortie ===")
layer = Layer(num_neurons=2, num_inputs=5)
inputs = [1, 2, 3, 4, 5]
outputs = layer.forward(inputs, activation=relu)
print(f"Couche : 2 neurones, 5 entrÃ©es")
print(f"EntrÃ©e : {inputs} (taille {len(inputs)})")
print(f"Sortie : {outputs} (taille {len(outputs)})")
print(f"Test {'âœ… OK' if len(outputs) == 2 else 'âŒ FAIL'}\n")

# Test 4 : Propagation avec ReLU
print("=== Test 4 : ReLU Ã©limine les nÃ©gatifs ===")
# CrÃ©er une couche avec des poids nÃ©gatifs
from neuron import Neuron
layer = Layer(num_neurons=2, num_inputs=2)
# Forcer des poids nÃ©gatifs pour avoir z < 0
layer.neurons[0] = Neuron(weights=[-1, -1], bias=0)
layer.neurons[1] = Neuron(weights=[1, 1], bias=0)

inputs = [1, 1]
outputs = layer.forward(inputs, activation=relu)
print(f"Neurone 1 : poids=[-1,-1], z=-2, ReLU(-2)=0")
print(f"Neurone 2 : poids=[1,1], z=2, ReLU(2)=2")
print(f"Sortie attendue : [0, 2]")
print(f"Sortie obtenue : {outputs}")
print(f"Test {'âœ… OK' if outputs == [0, 2] else 'âŒ FAIL'}\n")

print("=== Tests terminÃ©s ===")
```

**Lancer les tests :**
```bash
cd src
python test_layer.py
```

**Sortie attendue :**
```
=== Test 1 : CrÃ©ation d'une couche ===
Nombre de neurones crÃ©Ã©s : 3
Nombre de poids du 1er neurone : 2
Test âœ… OK

=== Test 2 : Forward pass ===
...
Test âœ… OK

=== Test 3 : Taille de sortie ===
...
Test âœ… OK

=== Test 4 : ReLU Ã©limine les nÃ©gatifs ===
...
Test âœ… OK

=== Tests terminÃ©s ===
```

---

## ğŸ¨ Visualiser le fonctionnement

Ajoute des prints pour voir ce qui se passe :

```python
def forward(self, inputs, activation):
    """Version avec debug"""
    print(f"=== Couche : {len(self.neurons)} neurones ===")
    print(f"EntrÃ©e : {inputs}")
    
    outputs = []
    for i, neuron in enumerate(self.neurons):
        output = neuron.compute(inputs, activation)
        print(f"  Neurone {i+1} â†’ sortie = {output:.3f}")
        outputs.append(output)
    
    print(f"Sortie : {outputs}\n")
    return outputs
```

---

## ğŸ› Debugging

### Erreur : "NameError: name 'Neuron' is not defined"

**ProblÃ¨me :** Tu n'as pas importÃ© la classe Neuron.

**Solution :**
```python
# Ajouter en haut du fichier
from neuron import Neuron
```

---

### Erreur : "ValueError: IncompatibilitÃ© dimensions"

**ProblÃ¨me :** Le nombre d'entrÃ©es ne correspond pas au nombre de poids.

**Solution :** VÃ©rifie que `num_inputs` correspond bien Ã  la taille du vecteur d'entrÃ©e.

```python
# Exemple
layer = Layer(num_neurons=3, num_inputs=2)
inputs = [1.0, 2.0]  # âœ… 2 entrÃ©es â†’ OK
inputs = [1.0, 2.0, 3.0]  # âŒ 3 entrÃ©es â†’ ERREUR
```

---

### Sortie vide []

**ProblÃ¨me :** Les neurones ne sont pas crÃ©Ã©s dans `__init__`.

**Solution :** VÃ©rifie que la boucle `for _ in range(num_neurons)` s'exÃ©cute bien.

```python
# Ajouter un print pour debug
def __init__(self, num_neurons, num_inputs):
    self.neurons = []
    print(f"CrÃ©ation de {num_neurons} neurones...")
    
    for i in range(num_neurons):
        weights = [random.uniform(-1, 1) for _ in range(num_inputs)]
        bias = random.uniform(-1, 1)
        neuron = Neuron(weights, bias)
        self.neurons.append(neuron)
        print(f"  Neurone {i+1} crÃ©Ã©")
```

---

## âœ… VÃ©rification finale

Avant de passer Ã  la suite, vÃ©rifie que :

- [ ] La classe `Layer` est dans `src/layer.py`
- [ ] Le constructeur crÃ©e bien `num_neurons` neurones
- [ ] Chaque neurone a `num_inputs` poids
- [ ] La mÃ©thode `forward()` retourne une liste de `num_neurons` valeurs
- [ ] Tous les tests passent (4/4 âœ…)
- [ ] Tu comprends le fonctionnement d'une couche

---

## ğŸ¯ RÃ©sumÃ©

Tu as crÃ©Ã© une **couche de neurones** capable de :
1. CrÃ©er plusieurs neurones avec initialisation alÃ©atoire
2. Propager un vecteur d'entrÃ©e Ã  travers tous les neurones
3. Collecter et retourner les sorties

**Ta couche peut maintenant transformer un vecteur [x1, x2, x3] en [y1, y2, y3, y4] !** ğŸ‰

---

## ğŸ“š Pour aller plus loin

### Bonus 1 : Initialisation avec des poids fixÃ©s

Ajoute un paramÃ¨tre optionnel pour passer des poids manuellement :

```python
def __init__(self, num_neurons, num_inputs, fixed_weights=None):
    """
    Args:
        fixed_weights (list of dict): Poids et biais pour chaque neurone
            Exemple: [{'w': [0.5, 0.2], 'b': 0.1}, ...]
    """
    self.neurons = []
    
    if fixed_weights:
        for params in fixed_weights:
            neuron = Neuron(params['w'], params['b'])
            self.neurons.append(neuron)
    else:
        # Poids alÃ©atoires (code existant)
        ...
```

### Bonus 2 : MÃ©thode __str__

```python
def __str__(self):
    return f"Layer({len(self.neurons)} neurones)"
```

---

**Prochaine Ã©tape :** [06 - ImplÃ©mentation Network](06_implementation_network.md)
