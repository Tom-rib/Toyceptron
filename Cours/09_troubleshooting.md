# 09 - Troubleshooting

> R√©soudre les probl√®mes courants

---

## üêõ Erreurs Python courantes

### 1. ImportError / ModuleNotFoundError

```
ImportError: No module named 'neuron'
```

**Causes :**
- Le fichier `neuron.py` n'existe pas
- Tu n'es pas dans le bon dossier

**Solutions :**
```bash
# V√©rifier que tu es dans le bon dossier
pwd
ls  # Doit afficher neuron.py, layer.py, network.py

# Si tu es dans toyceptron/, aller dans src/
cd src
```

---

### 2. IndexError: list index out of range

```
IndexError: list index out of range
```

**Causes :**
- Le vecteur d'entr√©e n'a pas la bonne taille
- L'architecture `layers` est mal d√©finie

**Exemple d'erreur :**
```python
# R√©seau cr√©√© avec layers=[2, 3, 1]
# Donc l'entr√©e doit avoir 2 valeurs
network = Network([2, 3, 1], 'relu')
network.forward([1])  # ‚ùå Erreur ! Il faut 2 valeurs
```

**Solution :**
```python
# V√©rifier les dimensions
network = Network([2, 3, 1], 'relu')
print(f"Taille d'entr√©e attendue : {len(network.layers[0].neurons[0].weights)}")

# Utiliser la bonne taille
network.forward([1, 0.5])  # ‚úÖ OK
```

---

### 3. TypeError: 'NoneType' object is not callable

```
TypeError: 'NoneType' object is not callable
```

**Cause :**
La fonction d'activation n'est pas pass√©e correctement.

**Erreur typique :**
```python
# ‚ùå Mauvais
output = neuron.compute([1, 2], activation=relu())  # () en trop

# ‚úÖ Bon
output = neuron.compute([1, 2], activation=relu)
```

---

### 4. ValueError: Incompatibilit√© dimensions

```
ValueError: Incompatibilit√© : 3 entr√©es, 2 poids
```

**Cause :**
Le nombre d'entr√©es ne correspond pas au nombre de poids.

**Debug :**
```python
# Ajouter des prints dans compute()
def compute(self, inputs, activation):
    print(f"Nombre d'entr√©es : {len(inputs)}")
    print(f"Nombre de poids : {len(self.weights)}")
    # ...
```

---

### 5. AttributeError: object has no attribute

```
AttributeError: 'Neuron' object has no attribute 'weights'
```

**Cause :**
Le constructeur `__init__` n'a pas √©t√© appel√© correctement.

**Solution :**
```python
# V√©rifier que __init__ d√©finit bien les attributs
class Neuron:
    def __init__(self, weights, bias):
        self.weights = weights  # ‚úÖ Important
        self.bias = bias        # ‚úÖ Important
```

---

## üîç Probl√®mes logiques

### 1. La sortie est toujours la m√™me

**Sympt√¥me :** Peu importe l'entr√©e, la sortie ne change pas.

**Causes possibles :**
- Les poids sont tous √† 0
- L'activation est mal impl√©ment√©e

**Debug :**
```python
# V√©rifier les poids
network = Network([2, 3, 1], 'relu')
for i, layer in enumerate(network.layers):
    print(f"Couche {i+1} :")
    for j, neuron in enumerate(layer.neurons):
        print(f"  Neurone {j+1} : poids={neuron.weights}, biais={neuron.bias}")
```

---

### 2. La sortie est toujours 0 avec ReLU

**Sympt√¥me :** Le r√©seau retourne toujours 0.

**Explication :**
ReLU met √† 0 toutes les valeurs n√©gatives. Si tous les neurones produisent des valeurs n√©gatives, la sortie sera 0.

**C'est normal !** Avec des poids al√©atoires, il peut arriver que :
```
z = Œ£(wi ¬∑ xi) + b < 0
ReLU(z) = 0
```

**Solutions :**
1. Essayer d'autres entr√©es
2. Recr√©er le r√©seau (nouveaux poids al√©atoires)
3. Utiliser une autre activation (identity, sigmoid)

---

### 3. Sigmoid retourne toujours ~0.5

**Sympt√¥me :** Toutes les sorties sont proches de 0.5.

**Explication :**
Si z est proche de 0, alors `sigmoid(0) ‚âà 0.5`.

**C'est normal** si les poids sont tr√®s petits ou si les entr√©es sont nulles.

**Test :**
```python
import math
print(math.exp(-0))  # 1
print(1 / (1 + 1))   # 0.5
```

---

### 4. Les r√©sultats changent √† chaque ex√©cution

**Sympt√¥me :** Relancer le programme donne des r√©sultats diff√©rents.

**Explication :**
Les poids sont initialis√©s **al√©atoirement** !

**C'est normal !** Si tu veux des r√©sultats reproductibles :

```python
import random
random.seed(42)  # Fixer la seed

# Maintenant les r√©sultats seront toujours les m√™mes
network = Network([2, 3, 1], 'relu')
```

---

## üß™ M√©thodes de debugging

### 1. Utiliser des prints

```python
# Dans neuron.py
def compute(self, inputs, activation):
    print(f"[DEBUG] Entr√©es : {inputs}")
    print(f"[DEBUG] Poids : {self.weights}")
    print(f"[DEBUG] Biais : {self.bias}")
    
    z = self.weighted_sum(inputs)
    print(f"[DEBUG] z (avant activation) : {z}")
    
    y = activation(z)
    print(f"[DEBUG] y (apr√®s activation) : {y}")
    
    return y
```

---

### 2. Tester avec des valeurs simples

**Toujours commencer par des valeurs faciles √† calculer :**

```python
# Test simple : poids=[1, 1, 1], biais=0, activation=identity
neuron = Neuron([1, 1, 1], 0)
result = neuron.compute([1, 2, 3], lambda x: x)
# R√©sultat attendu : 1+2+3 = 6

if result == 6:
    print("‚úÖ Neurone fonctionne")
else:
    print(f"‚ùå Attendu 6, obtenu {result}")
```

---

### 3. V√©rifier les dimensions

```python
# Script pour v√©rifier toutes les dimensions
def check_dimensions(network):
    print("=== V√©rification des dimensions ===")
    
    for i, layer in enumerate(network.layers):
        print(f"Couche {i+1} :")
        print(f"  Neurones : {len(layer.neurons)}")
        print(f"  Poids par neurone : {len(layer.neurons[0].weights)}")
    
    print("\nV√©rification : OK ‚úÖ")

network = Network([2, 5, 3, 1], 'relu')
check_dimensions(network)
```

---

### 4. Tester √©tape par √©tape

**Ne pas tout coder d'un coup !**

```python
# √âtape 1 : Tester le neurone seul
neuron = Neuron([1, 1], 0)
print(neuron.compute([2, 3], lambda x: x))  # Doit afficher 5

# √âtape 2 : Tester une couche
layer = Layer(2, 2)
print(len(layer.forward([1, 1], lambda x: x)))  # Doit afficher 2

# √âtape 3 : Tester le r√©seau
network = Network([2, 3, 1], 'relu')
print(network.forward([1, 1]))  # Doit afficher un nombre
```

---

## üö® Cas sp√©ciaux

### 1. Overflow avec exponentielles

**Erreur :**
```
OverflowError: math range error
```

**Cause :**
`math.exp(-x)` avec x tr√®s grand ‚Üí overflow

**Solution :**
```python
# Dans get_activation()
def sigmoid(x):
    # Limiter x pour √©viter l'overflow
    if x > 500:
        return 1.0
    if x < -500:
        return 0.0
    return 1 / (1 + math.exp(-x))
```

---

### 2. Division par z√©ro

**Erreur :**
```
ZeroDivisionError: division by zero
```

**Cause :**
Rare, mais peut arriver avec certaines fonctions custom.

**Solution :**
Ajouter des v√©rifications :
```python
def safe_divide(a, b):
    if b == 0:
        return 0
    return a / b
```

---

## üìä Checklist de debug

Quand quelque chose ne marche pas, v√©rifie dans l'ordre :

1. **Imports**
   - [ ] Tous les fichiers .py existent
   - [ ] Les imports sont corrects

2. **Structure des classes**
   - [ ] `__init__` d√©finit tous les attributs
   - [ ] Les m√©thodes sont bien indent√©es dans la classe

3. **Dimensions**
   - [ ] Le vecteur d'entr√©e a la bonne taille
   - [ ] Chaque couche a le bon nombre de poids

4. **Fonctions d'activation**
   - [ ] Les fonctions sont bien des fonctions (pas des appels)
   - [ ] Elles retournent un nombre

5. **Logique**
   - [ ] Le produit scalaire est correct
   - [ ] L'activation est appliqu√©e
   - [ ] Le forward pass propage bien √† travers toutes les couches

---

## üõ†Ô∏è Outils de debug

### Script de diagnostic complet

```python
# diagnostic.py
"""Script pour diagnostiquer les probl√®mes"""

def test_neuron():
    try:
        from neuron import Neuron
        n = Neuron([1, 1], 0)
        result = n.compute([1, 1], lambda x: x)
        assert result == 2, f"Attendu 2, obtenu {result}"
        print("‚úÖ Neuron : OK")
        return True
    except Exception as e:
        print(f"‚ùå Neuron : {e}")
        return False

def test_layer():
    try:
        from layer import Layer
        l = Layer(2, 2)
        result = l.forward([1, 1], lambda x: x)
        assert len(result) == 2, f"Attendu 2 sorties, obtenu {len(result)}"
        print("‚úÖ Layer : OK")
        return True
    except Exception as e:
        print(f"‚ùå Layer : {e}")
        return False

def test_network():
    try:
        from network import Network
        net = Network([2, 3, 1], 'relu')
        result = net.forward([1, 1])
        assert isinstance(result, (int, float)), f"Attendu un nombre, obtenu {type(result)}"
        print("‚úÖ Network : OK")
        return True
    except Exception as e:
        print(f"‚ùå Network : {e}")
        return False

if __name__ == "__main__":
    print("=== DIAGNOSTIC TOYCEPTRON ===\n")
    results = [
        test_neuron(),
        test_layer(),
        test_network()
    ]
    
    if all(results):
        print("\nüéâ Tout fonctionne !")
    else:
        print("\n‚ö†Ô∏è Certains composants ont des probl√®mes")
```

---

## üí° Conseils g√©n√©raux

1. **Lis les erreurs attentivement**
   - Python donne souvent la ligne exacte du probl√®me
   - Le dernier message d'erreur est le plus important

2. **Google est ton ami**
   - Cherche le message d'erreur exact
   - Regarde Stack Overflow

3. **Teste par petits morceaux**
   - Ne code pas tout d'un coup
   - Teste chaque fonction d√®s qu'elle est √©crite

4. **Prends des pauses**
   - Si tu bloques, fais une pause
   - Reviens avec un regard frais

5. **Demande de l'aide**
   - √Ä tes camarades
   - √Ä ton prof
   - Sur des forums (discord, reddit, etc.)

---

## üìû O√π trouver de l'aide

- **Documentation Python** : [docs.python.org](https://docs.python.org/fr/3/)
- **Stack Overflow** : Cherche ton erreur
- **Discord de ta promo** : Demande √† tes camarades
- **GitHub Issues** : Cr√©e une issue sur ton d√©p√¥t

---

**Prochaine √©tape :** [10 - Annexes](10_annexes.md)
