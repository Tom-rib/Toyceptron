# 06 - Impl√©mentation : Network

> Coder la classe Network, le r√©seau de neurones complet

---

## üéØ Objectif

Cr√©er la classe `Network` dans le fichier `src/network.py` qui :
- Cr√©e une **architecture compl√®te** de couches
- Fait circuler les donn√©es de l'**entr√©e √† la sortie**
- G√®re les **fonctions d'activation**

---

## üìã Sp√©cifications

### Attributs de la classe
```python
class Network:
    def __init__(self, layers, activation='relu'):
        self.layers = []  # Liste de Layer
        self.activation = activation  # Nom de la fonction d'activation
        # Cr√©er l'architecture du r√©seau
```

### M√©thodes requises
```python
def forward(self, inputs):
    """
    Propage l'entr√©e √† travers toutes les couches.
    
    Args:
        inputs (list): Vecteur d'entr√©e
        
    Returns:
        list: Sortie du r√©seau
    """
    # √Ä impl√©menter
```

---

## üßÆ Architecture d'un r√©seau

### Exemple de r√©seau
```
Entr√©e        Couche 1      Couche 2       Couche 3      Sortie
[x1, x2]  ‚Üí  [3 neurones] ‚Üí [5 neurones] ‚Üí [2 neurones] ‚Üí [y1, y2]
  (2)            (3)            (5)             (2)          (2)
```

**Notation :** `layers = [2, 3, 5, 2]`
- `layers[0]` = taille de l'entr√©e (2)
- `layers[1]` = taille de la couche 1 (3 neurones)
- `layers[2]` = taille de la couche 2 (5 neurones)
- `layers[3]` = taille de la couche 3 / sortie (2 neurones)

---

## üí° Algorithme

### √âtape 1 : Cr√©er les couches

Pour cr√©er un r√©seau `[2, 3, 5, 2]` :
- **Couche 1 :** 3 neurones, 2 entr√©es (= `layers[0]`)
- **Couche 2 :** 5 neurones, 3 entr√©es (= `layers[1]`)
- **Couche 3 :** 2 neurones, 5 entr√©es (= `layers[2]`)

**R√®gle :** Couche `i` a `layers[i]` neurones et `layers[i-1]` entr√©es.

**Pseudo-code :**
```
pour i allant de 1 √† len(layers)-1 :
    num_neurons = layers[i]
    num_inputs = layers[i-1]
    cr√©er Layer(num_neurons, num_inputs)
```

---

### √âtape 2 : Forward pass

Faire circuler les donn√©es de couche en couche :

```
current = input
pour chaque couche :
    current = couche.forward(current, activation)
retourner current
```

---

## üíª Impl√©mentation pas √† pas

### √âtape 1 : Squelette de la classe

Ouvre `src/network.py` :

```python
# src/network.py
from layer import Layer
import math

class Network:
    """
    Classe repr√©sentant un r√©seau de neurones multi-couches.
    
    Le r√©seau est une composition de couches qui transforment
    progressivement l'entr√©e jusqu'√† produire une sortie.
    """
    
    def __init__(self, layers, activation='relu'):
        """
        Initialise le r√©seau.
        
        Args:
            layers (list): Architecture du r√©seau [in, h1, h2, ..., out]
                Exemple: [2, 4, 3, 1] ‚Üí entr√©e:2, couche1:4, couche2:3, sortie:1
            activation (str): Nom de la fonction d'activation
                Choix: 'identity', 'step', 'sigmoid', 'relu'
        """
        self.layers = []
        self.activation_name = activation
        
        # TODO: Cr√©er les couches
        
        # TODO: D√©finir la fonction d'activation
    
    def forward(self, inputs):
        """
        Propage l'entr√©e √† travers le r√©seau.
        
        Args:
            inputs (list): Vecteur d'entr√©e
            
        Returns:
            list: Sortie du r√©seau
        """
        # TODO: Impl√©menter la propagation
        pass
```

---

### √âtape 2 : Cr√©er les couches dans __init__

```python
def __init__(self, layers, activation='relu'):
    """
    Initialise le r√©seau avec une architecture donn√©e.
    """
    self.layers = []
    self.activation_name = activation
    
    # Cr√©er les couches
    # On parcourt layers √† partir de l'indice 1
    for i in range(1, len(layers)):
        num_neurons = layers[i]      # Taille de la couche actuelle
        num_inputs = layers[i-1]     # Taille de la couche pr√©c√©dente
        
        # Cr√©er la couche et l'ajouter au r√©seau
        layer = Layer(num_neurons, num_inputs)
        self.layers.append(layer)
    
    # D√©finir la fonction d'activation
    self.activation = self.get_activation(activation)
```

**Exemple :** Pour `layers = [2, 3, 5, 2]`
```
i=1 : Layer(3 neurones, 2 entr√©es)
i=2 : Layer(5 neurones, 3 entr√©es)
i=3 : Layer(2 neurones, 5 entr√©es)

R√©sultat : 3 couches cr√©√©es
```

---

### √âtape 3 : Impl√©menter les fonctions d'activation

Ajoute une m√©thode pour r√©cup√©rer la fonction d'activation :

```python
def get_activation(self, name):
    """
    Retourne la fonction d'activation correspondante.
    
    Args:
        name (str): Nom de l'activation
        
    Returns:
        function: Fonction d'activation
    """
    if name == 'identity':
        return lambda x: x
    
    elif name == 'step':
        return lambda x: 1 if x >= 0 else 0
    
    elif name == 'sigmoid':
        return lambda x: 1 / (1 + math.exp(-x))
    
    elif name == 'relu':
        return lambda x: max(0, x)
    
    else:
        raise ValueError(f"Activation inconnue : {name}")
```

---

### √âtape 4 : Impl√©menter forward()

```python
def forward(self, inputs):
    """
    Propage l'entr√©e √† travers toutes les couches.
    
    Processus:
    1. Partir de l'entr√©e
    2. Pour chaque couche, transformer le vecteur courant
    3. Retourner la sortie de la derni√®re couche
    
    Args:
        inputs (list): Vecteur d'entr√©e
        
    Returns:
        list ou float: Sortie du r√©seau
    """
    current = inputs
    
    # Propager √† travers chaque couche
    for layer in self.layers:
        current = layer.forward(current, self.activation)
    
    # Si la sortie est un scalaire (1 neurone), retourner juste la valeur
    if len(current) == 1:
        return current[0]
    
    return current
```

---

## üìù Code complet de network.py

```python
# src/network.py
from layer import Layer
import math

class Network:
    """
    Classe repr√©sentant un r√©seau de neurones multi-couches.
    
    Attributs:
        layers (list): Liste des couches du r√©seau
        activation_name (str): Nom de la fonction d'activation
        activation (function): Fonction d'activation
    """
    
    def __init__(self, layers, activation='relu'):
        """
        Initialise le r√©seau avec une architecture.
        
        Args:
            layers (list): Architecture [entr√©e, h1, h2, ..., sortie]
                Exemple: [3, 5, 2] ‚Üí entr√©e:3, couche1:5, sortie:2
            activation (str): 'identity', 'step', 'sigmoid', 'relu'
        """
        self.layers = []
        self.activation_name = activation
        
        # Cr√©er les couches du r√©seau
        for i in range(1, len(layers)):
            num_neurons = layers[i]
            num_inputs = layers[i-1]
            layer = Layer(num_neurons, num_inputs)
            self.layers.append(layer)
        
        # D√©finir la fonction d'activation
        self.activation = self.get_activation(activation)
    
    def get_activation(self, name):
        """
        Retourne la fonction d'activation.
        
        Args:
            name (str): 'identity', 'step', 'sigmoid', 'relu'
            
        Returns:
            function: Fonction d'activation
        """
        if name == 'identity':
            return lambda x: x
        
        elif name == 'step':
            return lambda x: 1 if x >= 0 else 0
        
        elif name == 'sigmoid':
            return lambda x: 1 / (1 + math.exp(-x))
        
        elif name == 'relu':
            return lambda x: max(0, x)
        
        else:
            raise ValueError(f"Activation inconnue : {name}")
    
    def forward(self, inputs):
        """
        Propage l'entr√©e √† travers le r√©seau.
        
        Args:
            inputs (list): Vecteur d'entr√©e
            
        Returns:
            list ou float: Sortie du r√©seau
        """
        current = inputs
        
        # Propager √† travers toutes les couches
        for layer in self.layers:
            current = layer.forward(current, self.activation)
        
        # Si sortie scalaire (1 neurone), retourner la valeur
        if len(current) == 1:
            return current[0]
        
        return current
```

---

## üß™ Tests de validation

Cr√©e `test_network.py` :

```python
# test_network.py
from network import Network

# Test 1 : Cr√©ation d'un r√©seau
print("=== Test 1 : Cr√©ation d'un r√©seau ===")
network = Network(layers=[2, 3, 1], activation='relu')
print(f"Architecture : [2, 3, 1]")
print(f"Nombre de couches cr√©√©es : {len(network.layers)}")
print(f"Couche 1 : {len(network.layers[0].neurons)} neurones")
print(f"Couche 2 : {len(network.layers[1].neurons)} neurones")
print(f"Test {'‚úÖ OK' if len(network.layers) == 2 else '‚ùå FAIL'}\n")

# Test 2 : Forward pass simple
print("=== Test 2 : Forward pass ===")
network = Network(layers=[2, 3, 1], activation='identity')
output = network.forward([1.0, 0.5])
print(f"Entr√©e : [1.0, 0.5]")
print(f"Sortie : {output}")
print(f"Type : {type(output)}")
print(f"Test {'‚úÖ OK' if isinstance(output, (int, float)) else '‚ùå FAIL'}\n")

# Test 3 : R√©seau avec plusieurs sorties
print("=== Test 3 : Plusieurs sorties ===")
network = Network(layers=[3, 4, 2], activation='relu')
output = network.forward([1.0, 0.5, -0.3])
print(f"Architecture : [3, 4, 2]")
print(f"Entr√©e : [1.0, 0.5, -0.3] (3 valeurs)")
print(f"Sortie : {output}")
print(f"Taille sortie : {len(output)}")
print(f"Test {'‚úÖ OK' if len(output) == 2 else '‚ùå FAIL'}\n")

# Test 4 : ReLU √©limine les n√©gatifs
print("=== Test 4 : Activation ReLU ===")
network_relu = Network(layers=[2, 1], activation='relu')
network_identity = Network(layers=[2, 1], activation='identity')

inputs = [1.0, 2.0]
output_relu = network_relu.forward(inputs)
output_identity = network_identity.forward(inputs)

print(f"Entr√©e : {inputs}")
print(f"Sortie avec ReLU : {output_relu} (‚â• 0)")
print(f"Sortie avec identit√© : {output_identity} (peut √™tre < 0)")
print(f"Test {'‚úÖ OK' if output_relu >= 0 else '‚ùå FAIL'}\n")

# Test 5 : Sigmoid entre 0 et 1
print("=== Test 5 : Activation Sigmoid ===")
network = Network(layers=[2, 3, 1], activation='sigmoid')
output = network.forward([10.0, 5.0])
print(f"Entr√©e : [10.0, 5.0]")
print(f"Sortie : {output}")
print(f"Sigmoid ‚Üí sortie entre 0 et 1")
print(f"Test {'‚úÖ OK' if 0 <= output <= 1 else '‚ùå FAIL'}\n")

# Test 6 : R√©seau profond
print("=== Test 6 : R√©seau profond ===")
network = Network(layers=[2, 5, 4, 3, 1], activation='relu')
output = network.forward([1.0, 0.5])
print(f"Architecture : [2, 5, 4, 3, 1] (4 couches cach√©es)")
print(f"Entr√©e : [1.0, 0.5]")
print(f"Sortie : {output}")
print(f"Test {'‚úÖ OK' if isinstance(output, (int, float)) else '‚ùå FAIL'}\n")

print("=== Tests termin√©s ===")
```

**Lancer les tests :**
```bash
cd src
python test_network.py
```

---

## üé® Visualisation du r√©seau

Ajoute une m√©thode `summary()` pour afficher l'architecture :

```python
def summary(self):
    """
    Affiche un r√©sum√© de l'architecture du r√©seau.
    """
    print("=" * 50)
    print("R√âSUM√â DU R√âSEAU")
    print("=" * 50)
    print(f"Activation : {self.activation_name}")
    print(f"Nombre de couches : {len(self.layers)}")
    print("-" * 50)
    
    for i, layer in enumerate(self.layers):
        num_neurons = len(layer.neurons)
        num_inputs = len(layer.neurons[0].weights)
        num_params = num_neurons * (num_inputs + 1)  # poids + biais
        
        print(f"Couche {i+1} : {num_neurons} neurones")
        print(f"  Entr√©es : {num_inputs}")
        print(f"  Param√®tres : {num_params}")
        print()
    
    # Total de param√®tres
    total_params = sum(
        len(layer.neurons) * (len(layer.neurons[0].weights) + 1)
        for layer in self.layers
    )
    print("-" * 50)
    print(f"TOTAL PARAM√àTRES : {total_params}")
    print("=" * 50)
```

**Usage :**
```python
network = Network([3, 5, 4, 2], activation='relu')
network.summary()
```

**Sortie :**
```
==================================================
R√âSUM√â DU R√âSEAU
==================================================
Activation : relu
Nombre de couches : 3
--------------------------------------------------
Couche 1 : 5 neurones
  Entr√©es : 3
  Param√®tres : 20

Couche 2 : 4 neurones
  Entr√©es : 5
  Param√®tres : 24

Couche 3 : 2 neurones
  Entr√©es : 4
  Param√®tres : 10

--------------------------------------------------
TOTAL PARAM√àTRES : 54
==================================================
```

---

## üß™ Test avec le main.py fourni

Maintenant, teste avec le fichier `main.py` du projet :

```bash
cd src
python main.py
```

**Si tout fonctionne :** Tous les tests doivent passer ! ‚úÖ

---

## üêõ Debugging

### Erreur : "IndexError: list index out of range"

**Probl√®me :** L'architecture `layers` est mal d√©finie.

**Solution :** V√©rifie que `layers` a au moins 2 √©l√©ments :
```python
# ‚úÖ Bon
layers = [2, 3, 1]  # Minimum 2 √©l√©ments

# ‚ùå Mauvais
layers = [2]  # Pas assez d'√©l√©ments
```

---

### Erreur : "ValueError: Activation inconnue"

**Probl√®me :** Le nom de l'activation n'est pas reconnu.

**Solution :** Utilise un nom valide : `'identity'`, `'step'`, `'sigmoid'`, `'relu'`

---

### Sortie toujours 0 avec ReLU

**Probl√®me :** Tous les neurones produisent des valeurs n√©gatives.

**Explication :** C'est normal avec des poids al√©atoires ! ReLU met √† 0 les valeurs n√©gatives.

**Solution :** R√©essaye avec d'autres entr√©es ou recr√©√© le r√©seau (poids diff√©rents).

---

## ‚úÖ V√©rification finale

Avant de consid√©rer le projet termin√©, v√©rifie que :

- [ ] La classe `Network` est dans `src/network.py`
- [ ] Le r√©seau cr√©e le bon nombre de couches
- [ ] Les 4 activations fonctionnent (identity, step, sigmoid, relu)
- [ ] La m√©thode `forward()` propage correctement
- [ ] Le `main.py` fourni fonctionne sans erreur
- [ ] Tous les tests passent

---

## üéØ R√©sum√©

Tu as cr√©√© un **r√©seau de neurones complet** capable de :
1. Cr√©er une architecture multi-couches
2. Propager un vecteur de l'entr√©e √† la sortie
3. Utiliser 4 fonctions d'activation diff√©rentes
4. Transformer des donn√©es complexes

**Tu as maintenant un perceptron fonctionnel ! üéâüß†**

---

## üèÜ F√©licitations !

Tu as termin√© la partie obligatoire du projet Toyceptron !

**Tu as cod√© from scratch :**
- ‚úÖ Un neurone artificiel
- ‚úÖ Une couche de neurones
- ‚úÖ Un r√©seau multi-couches
- ‚úÖ 4 fonctions d'activation

**Prochaines √©tapes :**
1. [Tests et validation](07_tests_validation.md)
2. [Bonus](08_bonus.md) (optionnel)

---

**Prochaine √©tape :** [07 - Tests & Validation](07_tests_validation.md)
